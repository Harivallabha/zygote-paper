@article{bergholm2018pennylane,
  title={Pennylane: Automatic differentiation of hybrid quantum-classical computations},
  author={Bergholm, Ville and Izaac, Josh and Schuld, Maria and Gogolin, Christian and Killoran, Nathan},
  journal={arXiv preprint arXiv:1811.04968},
  year={2018}
}

@article{kandala2017hardware,
  title={Hardware-efficient variational quantum eigensolver for small molecules and quantum magnets},
  author={Kandala, Abhinav and Mezzacapo, Antonio and Temme, Kristan and Takita, Maika and Brink, Markus and Chow, Jerry M and Gambetta, Jay M},
  journal={Nature},
  volume={549},
  number={7671},
  pages={242},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{mitarai2018quantum,
  title={Quantum circuit learning},
  author={Mitarai, Kosuke and Negoro, Makoto and Kitagawa, Masahiro and Fujii, Keisuke},
  journal={Physical Review A},
  volume={98},
  number={3},
  pages={032309},
  year={2018},
  publisher={APS}
}

@article{liu2019variational,
  title={Variational Quantum Eigensolver with Fewer Qubits},
  author={Liu, Jin-Guo and Zhang, Yi-Hong and Wan, Yuan and Wang, Lei},
  journal={arXiv preprint arXiv:1902.02663},
  year={2019}
}

@article{liu2018differentiable,
  title={Differentiable learning of quantum circuit born machines},
  author={Liu, Jin-Guo and Wang, Lei},
  journal={Physical Review A},
  volume={98},
  number={6},
  pages={062324},
  year={2018},
  publisher={APS}
}

@article{preskill2018quantum,
  title={Quantum Computing in the NISQ era and beyond},
  author={Preskill, John},
  journal={Quantum},
  volume={2},
  pages={79},
  year={2018},
  publisher={Verein zur F{\"o}rderung des Open Access Publizierens in den Quantenwissenschaften}
}

@article{benedetti2019parameterized,
  title={Parameterized quantum circuits as machine learning models},
  author={Benedetti, Marcello and Lloyd, Erika and Sack, Stefan},
  journal={arXiv preprint arXiv:1906.07682},
  year={2019}
}

@article{hascoet2013tapenade,
  title={The Tapenade Automatic Differentiation tool: principles, model, and specification},
  author={Hascoet, Laurent and Pascual, Val{\'e}rie},
  journal={ACM Transactions on Mathematical Software (TOMS)},
  volume={39},
  number={3},
  pages={20},
  year={2013},
  publisher={ACM}
}

@article{pearlmutter2008reverse,
  title={Reverse-mode {AD} in a functional framework: Lambda the ultimate backpropagator},
  author={Pearlmutter, Barak A and Siskind, Jeffrey Mark},
  journal={ACM Transactions on Programming Languages and Systems (TOPLAS)},
  volume={30},
  number={2},
  pages={7},
  year={2008},
  publisher={ACM}
}

@article{wang2018demystifying,
  title={Demystifying differentiable programming: Shift/reset the penultimate backpropagator},
  author={Wang, Fei and Wu, Xilun and Essertel, Gregory and Decker, James and Rompf, Tiark},
  journal={arXiv preprint arXiv:1803.10228},
  year={2018}
}

@article{innes2018machine,
  title={On Machine Learning and Programming Languages},
  author={Innes, Mike and Karpinski, Stefan and Shah, Viral and Barber, David and Stenetorp, Pontus and Besard, Tim and Bradbury, James and Churavy, Valentin and Danisch, Simon and Edelman, Alan and others},
  year={2018}
}

@article{neubig2017dynet,
  title={Dynet: The dynamic neural network toolkit},
  author={Neubig, Graham and Dyer, Chris and Goldberg, Yoav and Matthews, Austin and Ammar, Waleed and Anastasopoulos, Antonios and Ballesteros, Miguel and Chiang, David and Clothiaux, Daniel and Cohn, Trevor and others},
  journal={arXiv preprint arXiv:1701.03980},
  year={2017}
}

@inproceedings{lattner2004llvm,
  title={{LLVM}: A compilation framework for lifelong program analysis \& transformation},
  author={Lattner, Chris and Adve, Vikram},
  booktitle={Proceedings of the international symposium on Code generation and optimization: feedback-directed and runtime optimization},
  pages={75},
  year={2004},
  organization={IEEE Computer Society}
}

@article{wengert1964simple,
  title={A simple automatic derivative evaluation program},
  author={Wengert, Robert Edwin},
  journal={Communications of the ACM},
  volume={7},
  number={8},
  pages={463--464},
  year={1964},
  publisher={ACM}
}

@article{bartholomew2000automatic,
  title={Automatic differentiation of algorithms},
  author={Bartholomew-Biggs, Michael and Brown, Steven and Christianson, Bruce and Dixon, Laurence},
  journal={Journal of Computational and Applied Mathematics},
  volume={124},
  number={1-2},
  pages={171--190},
  year={2000},
  publisher={Elsevier}
}

@article{giering1998recipes,
  title={Recipes for adjoint code construction},
  author={Giering, Ralf and Kaminski, Thomas},
  journal={ACM Transactions on Mathematical Software (TOMS)},
  volume={24},
  number={4},
  pages={437--474},
  year={1998},
  publisher={ACM}
}

@article{innes:2018,
  author    = {Mike Innes},
  title     = {Flux: Elegant Machine Learning with {J}ulia},
  journal   = {Journal of Open Source Software},
  year      = {2018},
  doi       = {10.21105/joss.00602},
}

@article{bezanson2017julia,
  title={Julia: A fresh approach to numerical computing},
  author={Bezanson, Jeff and Edelman, Alan and Karpinski, Stefan and Shah, Viral B},
  journal={SIAM review},
  volume={59},
  number={1},
  pages={65--98},
  year={2017},
  publisher={SIAM}
}

@article{cytron1991efficiently,
  title={Efficiently computing static single assignment form and the control dependence graph},
  author={Cytron, Ron and Ferrante, Jeanne and Rosen, Barry K and Wegman, Mark N and Zadeck, F Kenneth},
  journal={ACM Transactions on Programming Languages and Systems (TOPLAS)},
  volume={13},
  number={4},
  pages={451--490},
  year={1991},
  publisher={ACM}
}

@article{appel1998ssa,
  title={{SSA} is functional programming},
  author={Appel, Andrew W},
  journal={ACM SIGPLAN Notices},
  volume={33},
  number={4},
  pages={17--20},
  year={1998},
  publisher={ACM}
}

@inproceedings{bergstra2011theano,
  title={Theano: Deep learning on gpus with python},
  author={Bergstra, James and Bastien, Fr{\'e}d{\'e}ric and Breuleux, Olivier and Lamblin, Pascal and Pascanu, Razvan and Delalleau, Olivier and Desjardins, Guillaume and Warde-Farley, David and Goodfellow, Ian and Bergeron, Arnaud and others},
  booktitle={NIPS 2011, BigLearning Workshop, Granada, Spain},
  volume={3},
  pages={1--48},
  year={2011},
  organization={Citeseer}
}

@inproceedings{maclaurin2015autograd,
  title={Autograd: Effortless gradients in numpy},
  author={Maclaurin, Dougal and Duvenaud, David and Adams, Ryan P},
  booktitle={ICML 2015 AutoML Workshop},
  year={2015}
}

@article{moldovan2018autograph,
  title={AutoGraph: Imperative-style Coding with Graph-based Performance},
  author={Moldovan, Dan and Decker, James M and Wang, Fei and Johnson, Andrew A and Lee, Brian K and Nado, Zachary and Sculley, D and Rompf, Tiark and Wiltschko, Alexander B},
  journal={arXiv preprint arXiv:1810.08061},
  year={2018}
}

@article{jiang2018efficient,
  title={Efficient Deep Learning Inference on Edge Devices},
  author={Jiang, Ziheng and Chen, Tianqi and Li, Mu},
  year={2018}
}

@misc{frostig2018compiling,
  title={Compiling machine learning programs via high-level tracing},
  author={Frostig, Roy and Johnson, Matthew James and Leary, Chris},
  year={2018},
  publisher={SysML}
}

@techreport{speelpenning1980compiling,
  title={Compiling fast partial derivatives of functions given by algorithms},
  author={Speelpenning, Bert},
  year={1980},
  institution={Illinois Univ., Urbana (USA). Dept. of Computer Science}
}

@article{baydin2017automatic,
  title={Automatic differentiation in machine learning: a survey.},
  author={Baydin, Atilim Gunes and Pearlmutter, Barak A and Radul, Alexey Andreyevich and Siskind, Jeffrey Mark},
  journal={Journal of machine learning research},
  volume={18},
  number={153},
  pages={1--153},
  year={2017}
}

@misc{XLA,
  title = {{XLA} Overview},
  howpublished = {\url{tensorflow.org/performance/xla}},
  note = {Accessed: 2018-09-22},
  year={2018}
}

@misc{PyTorchYear,
  title = {{PyTorch}, a, year in...},
  author={{PyTorch Team}},
  year={2018},
  howpublished={\url{pytorch.org/blog/a-year-in}},
  note = {Accessed: 2018-09-22}
}

@misc{torchscript,
  title = {{TorchScript}},
  author={{PyTorch Team}},
  year={2019},
  howpublished={\url{pytorch.org/docs/stable/jit.html}},
  note = {Accessed: 2018-04-16}
}

@misc{swift,
  title = {{Swift} for {TensorFlow}},
  author={{Swift for TensorFlow Team}},
  year={2019},
  howpublished={\url{github.com/tensorflow/swift}},
  note = {Accessed: 2018-04-16}
}


@misc{cassette,
  title = {Cassette.jl},
  author={Jarrett Revels},
  year={2018},
  howpublished={\url{jrevels.github.io/Cassette.jl/v0.1.1}},
  note = {Accessed: 2018-09-22}
}

@misc{reversediff,
  title = {ReverseDiff.jl},
  author={Jarrett Revels},
  year={2018},
  howpublished={\url{github.com/JuliaDiff/ReverseDiff.jl}},
  note = {Accessed: 2018-09-22}
}

@article{paszke2017automatic,
  title={Automatic differentiation in pytorch},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  year={2017}
}

@inproceedings{abadi2016tensorflow,
  title={Tensorflow: a system for large-scale machine learning.},
  author={Abadi, Mart{\'\i}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and others},
  booktitle={OSDI},
  volume={16},
  pages={265--283},
  year={2016}
}

@article{DBLP:journals/corr/abs-1801-08058,
  author    = {Scott Cyphers and
               Arjun K. Bansal and
               Anahita Bhiwandiwalla and
               Jayaram Bobba and
               Matthew Brookhart and
               Avijit Chakraborty and
               William Constable and
               Christian Convey and
               Leona Cook and
               Omar Kanawi and
               Robert Kimball and
               Jason Knight and
               Nikolay Korovaiko and
               Varun Kumar and
               Yixing Lao and
               Christopher R. Lishka and
               Jaikrishnan Menon and
               Jennifer Myers and
               Sandeep Aswath Narayana and
               Adam Procter and
               Tristan J. Webb},
  title     = {Intel nGraph: An Intermediate Representation, Compiler, and Executor
               for Deep Learning},
  journal   = {CoRR},
  volume    = {abs/1801.08058},
  year      = {2018},
  url       = {http://arxiv.org/abs/1801.08058},
  archivePrefix = {arXiv},
  eprint    = {1801.08058},
  timestamp = {Mon, 13 Aug 2018 16:46:08 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1801-08058},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{wei2017dlvm,
  title={DLVM: A modern compiler infrastructure for deep learning},
  author={Wei, Richard and Adve, Vikram and Schwartz, Lane},
  journal={arXiv preprint arXiv:1711.03016},
  year={2017}
}

@article{chang2017reversible,
  title={Reversible architectures for arbitrarily deep residual neural networks},
  author={Chang, Bo and Meng, Lili and Haber, Eldad and Ruthotto, Lars and Begert, David and Holtham, Elliot},
  journal={arXiv preprint arXiv:1709.03698},
  year={2017}
}

@inproceedings{chen2018neural,
  title={Neural ordinary differential equations},
  author={Chen, Tian Qi and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David K},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6571--6583},
  year={2018}
}

@inproceedings{van2018automatic,
  title={Automatic differentiation in ML: Where we are and where we should be going},
  author={van Merri{\"e}nboer, Bart and Breuleux, Olivier and Bergeron, Arnaud and Lamblin, Pascal},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8770--8780},
  year={2018}
}

@misc{swifttf,
  title = {Swift for {TensorFlow}},
  author={Richard Wei and Dan Zheng and others},
  howpublished = {\url{github.com/tensorflow/swift}},
  note = {Accessed: 2018-09-22},
  year={2018}
}

@inproceedings{chen2018tvm,
  title={TVM: end-to-end compilation stack for deep learning},
  author={Chen, Tianqi and Moreau, Thierry and Jiang, Ziheng and Shen, Haichen and Yan, Eddie and Wang, Leyuan and Hu, Yuwei and Ceze, Luis and Guestrin, Carlos and Krishnamurthy, Arvind},
  booktitle={SysML Conference},
  year={2018}
}

@article{wiltschko2017tangent,
  title={Tangent: automatic differentiation using source code transformation in Python},
  author={Wiltschko, Alexander B and van Merri{\"e}nboer, Bart and Moldovan, Dan},
  year={2017}
}

@misc{swiftad,
  title = {First-class Automatic Differentition in Swift},
  author={Richard Wei},
  howpublished = {\url{gist.github.com/rxwei/30ba75ce092ab3b0dce4bde1fc2c9f1d}},
  note = {Accessed: 2018-09-22},
  year={2018}
}

@article{XLA.jl-2018,
  author    = {Keno Fischer and Elliot Saba},
  title     = {Automatic Full Compilation of {J}ulia Programs and {ML} Models to Cloud {TPU}s},
  journal   = {CoRR},
  volume    = {abs/1810.09868},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.09868},
  archivePrefix = {arXiv},
  eprint    = {1810.09868},
  timestamp = {Wed, 31 Oct 2018 14:24:29 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1810-09868},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{besard2018effective,
  title={Effective extensible programming: Unleashing julia on gpus},
  author={Besard, Tim and Foket, Christophe and De Sutter, Bjorn},
  journal={IEEE Transactions on Parallel and Distributed Systems},
  year={2018},
  publisher={IEEE}
}

@misc{innes2018dont,
    title={Don't Unroll Adjoint: Differentiating SSA-Form Programs},
    author={Michael Innes},
    year={2018},
    eprint={1810.07951},
    archivePrefix={arXiv},
    primaryClass={cs.PL}
}

@article{Julia-2017-a,
  title={Julia: A fresh approach to numerical computing},
  author={Bezanson, Jeff and Edelman, Alan and Karpinski, Stefan and Shah, Viral B},
  journal={SIAM {R}eview},
  volume={59},
  number={1},
  pages={65--98},
  year={2017},
  publisher={SIAM},
  url={https://doi.org/10.1137/141000671}
}

@inproceedings{atkeson1997comparison,
  title={A comparison of direct and model-based reinforcement learning},
  author={Atkeson, Christopher G and Santamaria, Juan Carlos},
  booktitle={Proceedings of International Conference on Robotics and Automation},
  volume={4},
  pages={3557--3564},
  year={1997},
  organization={IEEE}
}


@article{innes2018flux,
  title={Flux: Elegant machine learning with Julia},
  author={Innes, Mike},
  journal={Journal of Open Source Software},
  volume={3},
  number={25},
  pages={602},
  year={2018}
}

@article{Flux.jl-2018,
  author    = {Michael Innes and
               Elliot Saba and
               Keno Fischer and
               Dhairya Gandhi and
               Marco Concetto Rudilosso and
               Neethu Mariya Joy and
               Tejan Karmali and
               Avik Pal and
               Viral Shah},
  title     = {Fashionable Modelling with {F}lux},
  journal   = {CoRR},
  volume    = {abs/1811.01457},
  year      = {2018},
  url       = {http://arxiv.org/abs/1811.01457},
  archivePrefix = {arXiv},
  eprint    = {1811.01457},
  timestamp = {Thu, 22 Nov 2018 17:58:30 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1811-01457},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{pmlr-v5-alvarez09a,
  title = 	 {Latent Force Models},
  author = 	 {Mauricio Álvarez and David Luengo and Neil D. Lawrence},
  booktitle = 	 {Proceedings of the Twelth International Conference on Artificial Intelligence and Statistics},
  pages = 	 {9--16},
  year = 	 {2009},
  editor = 	 {David van Dyk and Max Welling},
  volume = 	 {5},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Hilton Clearwater Beach Resort, Clearwater Beach, Florida USA},
  month = 	 {16--18 Apr},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v5/alvarez09a/alvarez09a.pdf},
  url = 	 {http://proceedings.mlr.press/v5/alvarez09a.html},
  abstract = 	 {Purely data driven approaches for machine learning present difficulties when data is scarce relative to the complexity of the model or when the model is forced to extrapolate. On the other hand, purely mechanistic approaches  need to identify and specify all the interactions in the problem at hand (which  may not be feasible) and still leave the issue of how to parameterize the system. In this paper, we present a hybrid approach using Gaussian processes and differential equations to combine data driven modeling with a physical model of the system. We show how different, physically-inspired, kernel functions  can be developed through sensible, simple, mechanistic assumptions about the underlying system. The versatility of our approach is illustrated with three case studies from computational biology, motion capture and geostatistics.}
}

@article{latent,
author = {Hu, Yueqin and Boker, Steve and Neale, Michael and Klump, Kelly},
year = {2013},
month = {05},
pages = {},
title = {Coupled Latent Differential Equation With Moderators: Simulation and Application},
volume = {19},
journal = {Psychological methods},
doi = {10.1037/a0032476}
}

@article{He2016DeepRL,
  title={Deep Residual Learning for Image Recognition},
  author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
  journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016},
  pages={770-778}
}

@ARTICLE{2019arXiv190401681D,
       author = {{Dupont}, Emilien and {Doucet}, Arnaud and {Whye Teh}, Yee},
        title = "{Augmented Neural ODEs}",
      journal = {arXiv e-prints},
     keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
         year = "2019",
        month = "Apr",
          eid = {arXiv:1904.01681},
        pages = {arXiv:1904.01681},
archivePrefix = {arXiv},
       eprint = {1904.01681},
 primaryClass = {stat.ML},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv190401681D},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{DBLP:journals/corr/abs-1810-01367,
  author    = {Will Grathwohl and
               Ricky T. Q. Chen and
               Jesse Bettencourt and
               Ilya Sutskever and
               David K. Duvenaud},
  title     = {{FFJORD:} Free-form Continuous Dynamics for Scalable Reversible Generative
               Models},
  journal   = {CoRR},
  volume    = {abs/1810.01367},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.01367},
  archivePrefix = {arXiv},
  eprint    = {1810.01367},
  timestamp = {Tue, 30 Oct 2018 10:49:09 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1810-01367},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{10.1093/bioinformatics/btn278,
    author = {Gao, Pei and Honkela, Antti and Rattray, Magnus and Lawrence, Neil D.},
    title = "{Gaussian process modelling of latent chemical species: applications to inferring transcription factor activities}",
    journal = {Bioinformatics},
    volume = {24},
    number = {16},
    pages = {i70-i75},
    year = {2008},
    month = {08},
    abstract = "{Motivation: Inference of latent chemical species in biochemical interaction networks is a key problem in estimation of the structure and parameters of the genetic, metabolic and protein interaction networks that underpin all biological processes. We present a framework for Bayesian marginalization of these latent chemical species through Gaussian process priors.Results: We demonstrate our general approach on three different biological examples of single input motifs, including both activation and repression of transcription. We focus in particular on the problem of inferring transcription factor activity when the concentration of active protein cannot easily be measured. We show how the uncertainty in the inferred transcription factor activity can be integrated out in order to derive a likelihood function that can be used for the estimation of regulatory model parameters. An advantage of our approach is that we avoid the use of a coarsegrained discretization of continuous time functions, which would lead to a large number of additional parameters to be estimated. We develop exact (for linear regulation) and approximate (for non-linear regulation) inference schemes, which are much more efficient than competing sampling-based schemes and therefore provide us with a practical toolkit for model-based inference.Availability: The software and data for recreating all the experiments in this paper is available in MATLAB from http://www.cs.man.ac.uk/~neill/gpsim.Contact:neill@cs.man.ac.uk}",
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/btn278},
    url = {https://doi.org/10.1093/bioinformatics/btn278},
    eprint = {http://oup.prod.sis.lan/bioinformatics/article-pdf/24/16/i70/510191/btn278.pdf},
}

@article{ROMEROUGALDE2013170,
title = "Neural network design and model reduction approach for black box nonlinear system identification with reduced number of parameters",
journal = "Neurocomputing",
volume = "101",
pages = "170 - 180",
year = "2013",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2012.08.013",
url = "http://www.sciencedirect.com/science/article/pii/S0925231212006522",
author = "Hector M. Romero Ugalde and Jean-Claude Carmona and Victor M. Alvarado and Juan Reyes-Reyes",
keywords = "Nonlinear system identification, Black box, Neural Networks, Model reduction",
abstract = "In this paper a dedicated recurrent neural network design and a model reduction approach are proposed in order to improve the balance between complexity and quality of black box nonlinear system identification models. The proposed neural network design, based on a three-layers architecture, helps to reduce the number of parameters of the model after the training phase without any significant loss of estimation accuracy. Nevertheless, the proposed architecture remains sufficiently general to provide a wide range of models among the most encountered in the literature. This reduction, achieved by a convenient choice of the activation functions and the initial conditions of the synaptic weights, is developed in two steps. The first step is to train the proposed architecture under two reasonable assumptions. Then the recurrent three-layers neural network is transformed into a representation of two-layer with less number of neurons, that is, a significant reduced number of parameters. The constructed architecture provided models with reasonable reduced number of parameters with a convenient estimation accuracy. To validate the proposed approach, we identify the Wiener–Hammerstein benchmark nonlinear system proposed in SYSID2009 [1]."
}

@ARTICLE{2018arXiv180804930B,
       author = {{Bar-Sinai}, Yohai and {Hoyer}, Stephan and {Hickey}, Jason and
         {Brenner}, Michael P.},
        title = "{Data-driven discretization: machine learning for coarse graining of partial differential equations}",
      journal = {arXiv e-prints},
     keywords = {Condensed Matter - Disordered Systems and Neural Networks, Physics - Computational Physics},
         year = "2018",
        month = "Aug",
          eid = {arXiv:1808.04930},
        pages = {arXiv:1808.04930},
archivePrefix = {arXiv},
       eprint = {1808.04930},
 primaryClass = {cond-mat.dis-nn},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018arXiv180804930B},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{doi:10.1243/09544062JMES683,
author = {K Ordaz-Hernandez and X Fischer and F Bennis},
title ={Model reduction technique for mechanical behaviour modelling: Efficiency criteria and validity domain assessment},
journal = {Proceedings of the Institution of Mechanical Engineers, Part C: Journal of Mechanical Engineering Science},
volume = {222},
number = {3},
pages = {493-505},
year = {2008},
doi = {10.1243/09544062JMES683},

URL = { 
        https://doi.org/10.1243/09544062JMES683
    
},
eprint = { 
        https://doi.org/10.1243/09544062JMES683
    
}
,
    abstract = { The current paper presents the study of a neural network-based technique used to create fast, reduced, non-linear behavioural models. The studied approach is the use of artificial neural networks (ANNs) as a model reduction technique to create more efficient models, mostly in terms of computational speed. The test case is the deformation of a cantilever beam under large deflections (geometrical non-linearity). A reduced model is created by means of a multi-layer feed-forward neural network, a type of ANN reported as ‘universal approximator’ in the literature. Then it is compared with two finite-element models: linear (inaccurate for large deflections but fast) and non-linear (accurate but slow). Under large displacements, the reduced model approximates well the non-linear model while having similar speed to the linear model. Unfortunately, the resulting model presents a shortening of its validity domain, as being incapable of approximating the deformed configuration of the cantilever beam under small displacements. In other words, the ANN-based model provides a very good compromise between accuracy and speed within its validity domain, despite the low fidelity presented: accurate for large displacements but inaccurate for small displacements. }
}

@article {Han8505,
	author = {Han, Jiequn and Jentzen, Arnulf and E, Weinan},
	title = {Solving high-dimensional partial differential equations using deep learning},
	volume = {115},
	number = {34},
	pages = {8505--8510},
	year = {2018},
	doi = {10.1073/pnas.1718942115},
	publisher = {National Academy of Sciences},
	abstract = {Partial differential equations (PDEs) are among the most ubiquitous tools used in modeling problems in nature. However, solving high-dimensional PDEs has been notoriously difficult due to the {\textquotedblleft}curse of dimensionality.{\textquotedblright} This paper introduces a practical algorithm for solving nonlinear PDEs in very high (hundreds and potentially thousands of) dimensions. Numerical results suggest that the proposed algorithm is quite effective for a wide variety of problems, in terms of both accuracy and speed. We believe that this opens up a host of possibilities in economics, finance, operational research, and physics, by considering all participating agents, assets, resources, or particles together at the same time, instead of making ad hoc assumptions on their interrelationships.Developing algorithms for solving high-dimensional partial differential equations (PDEs) has been an exceedingly difficult task for a long time, due to the notoriously difficult problem known as the {\textquotedblleft}curse of dimensionality.{\textquotedblright} This paper introduces a deep learning-based approach that can handle general high-dimensional parabolic PDEs. To this end, the PDEs are reformulated using backward stochastic differential equations and the gradient of the unknown solution is approximated by neural networks, very much in the spirit of deep reinforcement learning with the gradient acting as the policy function. Numerical results on examples including the nonlinear Black{\textendash}Scholes equation, the Hamilton{\textendash}Jacobi{\textendash}Bellman equation, and the Allen{\textendash}Cahn equation suggest that the proposed algorithm is quite effective in high dimensions, in terms of both accuracy and cost. This opens up possibilities in economics, finance, operational research, and physics, by considering all participating agents, assets, resources, or particles together at the same time, instead of making ad hoc assumptions on their interrelationships.},
	issn = {0027-8424},
	URL = {https://www.pnas.org/content/115/34/8505},
	eprint = {https://www.pnas.org/content/115/34/8505.full.pdf},
	journal = {Proceedings of the National Academy of Sciences}
}

@ARTICLE{2018arXiv181108967P,
       author = {{Pang}, Guofei and {Lu}, Lu and {Karniadakis}, George Em},
        title = "{fPINNs: Fractional Physics-Informed Neural Networks}",
      journal = {arXiv e-prints},
     keywords = {Physics - Computational Physics},
         year = "2018",
        month = "Nov",
          eid = {arXiv:1811.08967},
        pages = {arXiv:1811.08967},
archivePrefix = {arXiv},
       eprint = {1811.08967},
 primaryClass = {physics.comp-ph},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018arXiv181108967P},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{DifferentialEquations.jl-2017,
 author = {Rackauckas, Christopher and Nie, Qing},
 doi = {10.5334/jors.151},
 journal = {},
 keywords = {Applied Mathematics},
 note = {Exported from https://app.dimensions.ai on 2019/05/05},
 number = {1},
 pages = {},
 title = {DifferentialEquations.jl – A Performant and Feature-Rich Ecosystem for Solving Differential Equations in Julia},
 url = {https://app.dimensions.ai/details/publication/pub.1085583166 and http://openresearchsoftware.metajnl.com/articles/10.5334/jors.151/galley/245/download/},
 volume = {5},
 year = {2017}
}

@ARTICLE{2018arXiv181201892R,
       author = {{Rackauckas}, Christopher and {Ma}, Yingbo and {Dixit}, Vaibhav and
         {Guo}, Xingjian and {Innes}, Mike and {Revels}, Jarrett and
         {Nyberg}, Joakim and {Ivaturi}, Vijay},
        title = "{A Comparison of Automatic Differentiation and Continuous Sensitivity Analysis for Derivatives of Differential Equation Solutions}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Numerical Analysis},
         year = "2018",
        month = "Dec",
          eid = {arXiv:1812.01892},
        pages = {arXiv:1812.01892},
archivePrefix = {arXiv},
       eprint = {1812.01892},
 primaryClass = {cs.NA},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018arXiv181201892R},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{Hindmarsh:2005:SSN:1089014.1089020,
 author = {Hindmarsh, Alan C. and Brown, Peter N. and Grant, Keith E. and Lee, Steven L. and Serban, Radu and Shumaker, Dan E. and Woodward, Carol S.},
 title = {SUNDIALS: Suite of Nonlinear and Differential/Algebraic Equation Solvers},
 journal = {ACM Trans. Math. Softw.},
 issue_date = {September 2005},
 volume = {31},
 number = {3},
 month = sep,
 year = {2005},
 issn = {0098-3500},
 pages = {363--396},
 numpages = {34},
 url = {http://doi.acm.org/10.1145/1089014.1089020},
 doi = {10.1145/1089014.1089020},
 acmid = {1089020},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {DAEs, ODEs, nonlinear systems, sensitivity analysis},
} 

@article{Rackauckas2017ADAPTIVEMF,
  title={ADAPTIVE METHODS FOR STOCHASTIC DIFFERENTIAL EQUATIONS VIA NATURAL EMBEDDINGS AND REJECTION SAMPLING WITH MEMORY.},
  author={Christopher V Rackauckas and Qing Nie},
  journal={Discrete and continuous dynamical systems. Series B},
  year={2017},
  volume={22 7},
  pages={
          2731-2761
        }
}

@INPROCEEDINGS{8062736, 
author={D. {Hartman} and L. K. {Mestha}}, 
booktitle={2017 IEEE Conference on Control Technology and Applications (CCTA)}, 
title={A deep learning framework for model reduction of dynamical systems}, 
year={2017}, 
volume={}, 
number={}, 
pages={1917-1922}, 
keywords={biology computing;diseases;feature extraction;learning (artificial intelligence);neural nets;principal component analysis;reduced order systems;state-space methods;proper orthogonal decomposition;balanced truncation;feature decomposition;neural network;state-space systems;nonlinear feature learning;spreading infectious disease dynamical system;model-order reduction methods;nonlinear feature extraction;deep learning;dynamical systems;representative data matrix;Feature extraction;Principal component analysis;Aerospace electronics;Autonomous systems;Covariance matrices;Decoding;Method of moments}, 
doi={10.1109/CCTA.2017.8062736}, 
ISSN={}, 
month={Aug},}

@article{DBLP:journals/corr/abs-1902-02376,
  author    = {Christopher Rackauckas and
               Mike Innes and
               Yingbo Ma and
               Jesse Bettencourt and
               Lyndon White and
               Vaibhav Dixit},
  title     = {DiffEqFlux.jl - {A} Julia Library for Neural Differential Equations},
  journal   = {CoRR},
  volume    = {abs/1902.02376},
  year      = {2019},
  url       = {http://arxiv.org/abs/1902.02376},
  archivePrefix = {arXiv},
  eprint    = {1902.02376},
  timestamp = {Fri, 01 Mar 2019 17:14:16 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1902-02376},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Hochreiter:1997:lstm,
 author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
 title = {Long Short-Term Memory},
 journal = {Neural Comput.},
 issue_date = {November 15, 1997},
 volume = {9},
 number = {8},
 month = nov,
 year = {1997},
 issn = {0899-7667},
 pages = {1735--1780},
 numpages = {46},
 url = {http://dx.doi.org/10.1162/neco.1997.9.8.1735},
 doi = {10.1162/neco.1997.9.8.1735},
 acmid = {1246450},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
}

@misc{chollet2015keras,
  title={Keras},
  author={Chollet, Fran\c{c}ois and others},
  year={2015},
  howpublished={\url{https://keras.io}},
}

@article{Degrave_2019,
   title={A Differentiable Physics Engine for Deep Learning in Robotics},
   volume={13},
   ISSN={1662-5218},
   url={http://dx.doi.org/10.3389/fnbot.2019.00006},
   DOI={10.3389/fnbot.2019.00006},
   journal={Frontiers in Neurorobotics},
   publisher={Frontiers Media SA},
   author={Degrave, Jonas and Hermans, Michiel and Dambre, Joni and wyffels, Francis},
   year={2019},
   month={Mar}
}

@inproceedings{de2018end,
  title={End-to-end differentiable physics for learning and control},
  author={de Avila Belbute-Peres, Filipe and Smith, Kevin and Allen, Kelsey and Tenenbaum, Josh and Kolter, J Zico},
  booktitle={Advances in Neural Information Processing Systems},
  pages={7178--7189},
  year={2018}
}

@article{blas,
  title={Algorithm 679: A set of level 3 basic linear algebra subprograms: model implementation and test programs},
  author={Dongarra, Jack J and Cruz, Jermey Du and Hammarling, Sven and Duff, Iain S},
  journal={ACM Transactions on Mathematical Software (TOMS)},
  volume={16},
  number={1},
  pages={18--28},
  year={1990},
  publisher={ACM}
}

@book{lapack,
  title={LAPACK Users' guide},
  author={Anderson, Edward and Bai, Zhaojun and Bischof, Christian and Blackford, Susan and Dongarra, Jack and Du Croz, Jeremy and Greenbaum, Anne and Hammarling, Sven and McKenney, Alan and Sorensen, D},
  volume={9},
  year={1999},
  publisher={{SIAM}}
}

@book{mpi,
  title={MPI - A Message Passing Interface Standard},
  publisher={MPI Forum},
  year={2015}
}

@inproceedings{gordon-bell-2018-a,
  title={Exascale deep learning for climate analytics},
  author={Kurth, Thorsten and Treichler, Sean and Romero, Joshua and Mudigonda, Mayur and Luehr, Nathan and Phillips, Everett and Mahesh, Ankur and Matheson, Michael and Deslippe, Jack and Fatica, Massimiliano and others},
  booktitle={Proceedings of the International Conference for High Performance Computing, Networking, Storage, and Analysis},
  pages={51},
  year={2018},
  organization={IEEE Press}
}

@article{flux,
  title={Fashionable Modelling with Flux},
  author={Innes, Michael and Saba, Elliot and Fischer, Keno and Gandhi, Dhairya and Rudilosso, Marco Concetto and Joy, Neethu Mariya and Karmali, Tejan and Singh, Avik Pal and Shah, Viral},
  journal={arXiv preprint arXiv:1811.01457},
  year={2018}
}


@inproceedings{theano,
  title={Theano: Deep learning on gpus with python},
  author={Bergstra, James and Bastien, Fr{\'e}d{\'e}ric and Breuleux, Olivier and Lamblin, Pascal and Pascanu, Razvan and Delalleau, Olivier and Desjardins, Guillaume and Warde-Farley, David and Goodfellow, Ian and Bergeron, Arnaud and others},
  booktitle={NIPS 2011, BigLearning Workshop, Granada, Spain},
  volume={3},
  pages={1--48},
  year={2011},
  organization={Citeseer}
}

@inproceedings{tensorflow,
  title={Tensorflow: A system for large-scale machine learning},
  author={Abadi, Mart{\'\i}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and others},
  booktitle={12th $\{$USENIX$\}$ Symposium on Operating Systems Design and Implementation ($\{$OSDI$\}$ 16)},
  pages={265--283},
  year={2016}
}

@misc{pytorch,
  title = {The Road to 1.0: production ready {PyTorch}},
  author={{PyTorch Team}},
  year={2018},
  howpublished={\url{https://pytorch.org/blog/a-year-in/}},
  note = {Accessed: 2018-09-22}
}
I
@misc{jax,
  title = {{JAX}: Autograd and XLA},
  author={Matt Johnson and Roy Frostig and Dougal Maclaurin and Chris Leary},
  year={2018},
  howpublished={\url{https://github.com/google/jax}},
}

@misc{xla.jl,
  title = {{XLA}.jl: Compiling {J}ulia to {XLA}},
  author={Keno Fischer and Elliot Saba},
  year={2018},
  howpublished={\url{https://github.com/JuliaTPU/XLA.jl}},
}

@article{adifor,
  title={{ADIFOR} 2.0: Automatic differentiation of {F}ortran 77 programs},
  author={Bischof, Christian and Khademi, Peyvand and Mauer, Andrew and Carle, Alan},
  journal={IEEE Computational Science and Engineering},
  volume={3},
  number={3},
  pages={18--32},
  year={1996},
  publisher={IEEE}
}

@article{baydin2018automatic,
  title={Automatic differentiation in machine learning: a survey},
  author={Baydin, Atilim Gunes and Pearlmutter, Barak A and Radul, Alexey Andreyevich and Siskind, Jeffrey Mark},
  journal={Journal of Marchine Learning Research},
  volume={18},
  pages={1--43},
  year={2018},
  publisher={Microtome Publishing}
}

@misc{rlvsdp,
  title = {Reinforcement Learning vs. Differentiable Programming},
  author={Mike Innes and Neethu Maria Joy and Tejan Karmali},
  year={2019},
  howpublished={\url{https://fluxml.ai/2019/03/05/dp-vs-rl.html}},
}

@misc{yao.jl,
    title = {Yao.jl: Extensible, Efficient Quantum Algorithm Design for Humans},
    author={Xiu-zhe Luo and Jin-guo Liu and Pan Zhang and Lei Wang},
    year = {2019},
    howpublished={In preparation}
}

@ARTICLE{Measurements.jl-2016,
  author =	 {{Giordano}, Mos{\`e}},
  title =	 "{Uncertainty propagation with functionally correlated
                  quantities}",
  journal =	 {ArXiv e-prints},
  archivePrefix ="arXiv",
  eprint =	 {1610.08716},
  primaryClass = "physics.data-an",
  keywords =	 {Physics - Data Analysis, Statistics and Probability},
  year =	 2016,
  month =	 oct,
  adsurl =	 {https://ui.adsabs.harvard.edu/abs/2016arXiv161008716G},
  adsnote =	 {Provided by the SAO/NASA Astrophysics Data System}
}

@article{Zygote.jl-2018,
  author    = {Michael Innes},
  title     = {Don't Unroll Adjoint: Differentiating {SSA}-Form Programs},
  journal   = {CoRR},
  volume    = {abs/1810.07951},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.07951},
  archivePrefix = {arXiv},
  eprint    = {1810.07951},
  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1810-07951},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Turing.jl-2018,
  author    = {Hong Ge and
               Kai Xu and
               Zoubin Ghahramani},
  title     = {Turing: Composable inference for probabilistic programming},
  booktitle = {International Conference on Artificial Intelligence and Statistics,
               {AISTATS} 2018, 9-11 April 2018, Playa Blanca, Lanzarote, Canary Islands,
               Spain},
  pages     = {1682--1690},
  year      = {2018},
  url       = {http://proceedings.mlr.press/v84/ge18b.html},
  timestamp = {Wed, 03 Apr 2019 18:17:22 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/aistats/GeXG18},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Gen.jl-2019,
 author = {Cusumano-Towner, Marco F. and Saad, Feras A. and Lew, Alexander K. and Mansinghka, Vikash K.},
 title = {Gen: A General-purpose Probabilistic Programming System with Programmable Inference},
 booktitle = {Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation},
 series = {PLDI 2019},
 year = {2019},
 isbn = {978-1-4503-6712-7},
 location = {Phoenix, AZ, USA},
 pages = {221--236},
 numpages = {16},
 url = {http://doi.acm.org/10.1145/3314221.3314642},
 doi = {10.1145/3314221.3314642},
 acmid = {3314642},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Markov chain Monte Carlo, Probabilistic programming, sequential Monte Carlo, variational inference},
} 

@article{doi:10.1137/S0363012902419059,
author = {Gobet, E. and Munos, R.},
title = {Sensitivity Analysis Using {I}tô--{M}alliavin Calculus and Martingales, and Application to Stochastic Optimal Control},
journal = {SIAM Journal on Control and Optimization},
volume = {43},
number = {5},
pages = {1676-1713},
year = {2005},
doi = {10.1137/S0363012902419059},

URL = { 
        https://doi.org/10.1137/S0363012902419059
    
},
eprint = { 
        https://doi.org/10.1137/S0363012902419059
    
}

}

@incollection{huang2000malliavin,
  title={Malliavin Calculus},
  author={Huang, Zhi-yuan and Yan, Jia-an},
  booktitle={Introduction to Infinite Dimensional Stochastic Analysis},
  pages={59--112},
  year={2000},
  publisher={Springer}
}
@phdthesis{zhang_2004, title={The Malliavan Calculus}, author={Zhang, Han}, year={2004}}

@article{jones2000composing,
  title={Composing contracts: an adventure in financial engineering},
  author={Jones, S Peyton and Eber, Jean-Marc and Seward, Julian},
  journal={ACM SIG-PLAN Notices},
  volume={35},
  number={9},
  pages={280--292},
  year={2000}
}

@article{jones2003write,
  title={How to write a financial contract},
  author={Jones, SL Peyton and Eber, Jean-Marc},
  year={2003},
  publisher={Citeseer}
}

@misc{Miletus.jl-2019,
  title={Miletus: Writing financial contracts in Julia},
  author={Simon Byrne},
  year={2019},
  url={https://github.com/JuliaComputing/Miletus.jl}
}

@inproceedings{li2018differentiable,
  title={Differentiable monte carlo ray tracing through edge sampling},
  author={Li, Tzu-Mao and Aittala, Miika and Durand, Fr{\'e}do and Lehtinen, Jaakko},
  booktitle={SIGGRAPH Asia 2018 Technical Papers},
  pages={222},
  year={2018},
  organization={ACM}
}

@article{2019sbc,
  title={{J}ulia {E} {F}lux: {M}odernizando O {A}prendizado De {M}áquina},
  author={Gandhi, Dhairya and Innes, Michael and Saba, Elliot and Fischer, Keno and Shah, Viral},
  url={https://www.sbc.org.br/component/flippingbook/book/43/1?page=41},
  pages={5},
  year={2019},
  publisher={SBC}
}

@article{diffrender,
  author    = {Avik Pal},
  title     = {RayTracer.jl: {A} Differentiable Renderer that supports Parameter Optimization for Scene Reconstruction},
  journal   = {CoRR},
  volume    = {abs/1907.07198},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.07198},
  archivePrefix = {arXiv},
  eprint    = {1907.07198},
  timestamp = {Tue, 23 Jul 2019 10:54:22 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1907-07198},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
